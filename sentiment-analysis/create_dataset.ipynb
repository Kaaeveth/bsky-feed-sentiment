{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dataset creation\n",
    "We first relabel the tweets dataset (test.csv and train.csv) using a *teacher* LLM.\n",
    "The reason for this is that:\n",
    "1. The existing labels are not quite accurate\n",
    "2. We also want to recognize \"neutral\" posts\n",
    "\n",
    "We do not preprocess (remove stopwords, normalization, etc.) the tweets since LLMs are trained on natural texts\n",
    "and therefore doing so would degrade performance."
   ],
   "id": "73f893dd3a01df18"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-20T13:39:56.357881Z",
     "start_time": "2025-07-20T13:39:44.433900Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from logit_processor import ConstrainedLogitProcessor\n",
    "from common import SENTIMENTS"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dstru\\miniconda3\\envs\\bsky-feed-sentiment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:39:56.469567Z",
     "start_time": "2025-07-20T13:39:56.365878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "OUTPUT_PATH = \"../data/tweet_sentiments.csv\"\n",
    "print(torch.__version__, \"Device:\", device)\n",
    "print(transformers.__version__)"
   ],
   "id": "d5283bfbc913ae8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu126 Device: cuda\n",
      "4.53.2\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Prepare tweet data\n",
    "We won't be using the provided train/test split."
   ],
   "id": "2e5efa74015d3789"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:39:57.538733Z",
     "start_time": "2025-07-20T13:39:56.752465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    # Continue from a previous session, if any\n",
    "    df = pd.read_csv(OUTPUT_PATH)\n",
    "except:\n",
    "    df_train = pd.read_csv(\"../data/train.csv\")\n",
    "    df_test = pd.read_csv(\"../data/test.csv\")\n",
    "    df = pd.concat((df_train, df_test), ignore_index=True)\n",
    "    df[\"sentiment\"] = -1 # Remove labels"
   ],
   "id": "6078dc2403d2fc7d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:39:57.572346Z",
     "start_time": "2025-07-20T13:39:57.560291Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "456f1c403c94341d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   sentiment                                               text\n",
       "0         -1        @tonigirl14 love you toooooo!! TG  LOL Gngb\n",
       "1         -1  @jun6lee I told myself: Don't click on this li...\n",
       "2         -1  The man who rendered his voice to Mickey Mouse...\n",
       "3         -1  @Shontelle_Layne I think red would be nice.  O...\n",
       "4         -1  @Silverlines - I guess. 'Cause one of her twee..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>@tonigirl14 love you toooooo!! TG  LOL Gngb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>@jun6lee I told myself: Don't click on this li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>The man who rendered his voice to Mickey Mouse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>@Shontelle_Layne I think red would be nice.  O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>@Silverlines - I guess. 'Cause one of her twee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Prepare the LLM<br>\n",
    "We configure the model so that it only outputs one token for each sentiment.\n",
    "We encode each sentiment as follows:\n",
    "* -1: Missing label\n",
    "* 0: negative\n",
    "* 1: neutral\n",
    "* 2: positive"
   ],
   "id": "fde5b3dc3fb8203c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:40:27.923590Z",
     "start_time": "2025-07-20T13:39:57.634968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"F:/Models/deepseek-llm-7b-chat\" # Or use deepseek-ai/deepseek-llm-7b-chat to directly download it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=device)"
   ],
   "id": "75db47dcb7670281",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.16s/it]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Constrain output to sentiment tokens.\n",
    "Our implementation only works for sentiment labels which make up exactly one token."
   ],
   "id": "d0f4a7589683ec86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:40:28.300926Z",
     "start_time": "2025-07-20T13:40:28.242903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentiment_tokens = [tokenizer.encode(term, add_special_tokens=False)[0] for term in SENTIMENTS.keys()]\n",
    "print(sentiment_tokens)\n",
    "assert len(sentiment_tokens) == len(SENTIMENTS)\n",
    "sentiment_logit_processor = ConstrainedLogitProcessor(sentiment_tokens)"
   ],
   "id": "1760fad64c218ded",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20805, 35413, 28573]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:40:29.247426Z",
     "start_time": "2025-07-20T13:40:29.243914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a specialist in analyzing the sentiments of texts. The user provides you with a text and you only determine and output the sentiment of the text. You must only output one of: negative, neutral, positive - nothing else. Answer with neutral if you cannot confidently identify the sentiment. Pay attention to the language of the text and answer with its slangs in mind.\"\n",
    "}"
   ],
   "id": "3632a79aaf87ee30",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Label the tweets",
   "id": "4842dbfbc7eeb42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:40:29.296254Z",
     "start_time": "2025-07-20T13:40:29.290468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prompt_sentiment(texts: list[str]) -> list[str]:\n",
    "    input_prompts = [\n",
    "        tokenizer.apply_chat_template([system_prompt, {\"role\": \"user\", \"content\": text}], tokenize=False, add_generation_prompt=True)\n",
    "        for text in texts\n",
    "    ]\n",
    "    input_tensor = tokenizer(input_prompts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    outputs = model.generate(\n",
    "        **input_tensor,\n",
    "        max_new_tokens=1,\n",
    "        do_sample=False,\n",
    "        temperature=None,\n",
    "        top_p=None,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        logits_processor=[sentiment_logit_processor]\n",
    "    )\n",
    "    res = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        prompt_len = input_tensor['input_ids'][i].shape[0]\n",
    "        generated_tokens = output[prompt_len:]\n",
    "        res.append(tokenizer.decode(generated_tokens, skip_special_tokens=True).strip())\n",
    "    return res"
   ],
   "id": "383fe7bbb194be76",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:40:30.942167Z",
     "start_time": "2025-07-20T13:40:29.338779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing...\n",
    "prompt_sentiment([\"What a good day!\", \"What a shit day!\", \"What a meh day\", \"Der Bundesrechnungshof warnt vor Finanzklemme beim Klima- und Transformationsfonds.\"])"
   ],
   "id": "f36f4ea0076a4a86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative', 'neutral', 'negative']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T17:57:52.632790Z",
     "start_time": "2025-07-20T13:42:10.574526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 8\n",
    "target_idx = df.columns.get_loc(\"sentiment\")\n",
    "start_idx = 0\n",
    "\n",
    "try:\n",
    "    start_idx = df[df[\"sentiment\"] < 0].index[0]\n",
    "    print(\"Resuming from idx:\", start_idx)\n",
    "except: pass\n",
    "\n",
    "try:\n",
    "    for i in tqdm(range(start_idx, len(df), BATCH_SIZE), total=len(df)//BATCH_SIZE):\n",
    "        df_batch = df.iloc[i:i+BATCH_SIZE]\n",
    "        sentiment_output = prompt_sentiment(df_batch.text.tolist())\n",
    "        labels = [SENTIMENTS.get(sentiment, -1) for sentiment in sentiment_output]\n",
    "        df.iloc[i:i+BATCH_SIZE, target_idx] = labels\n",
    "finally:\n",
    "    df.to_csv(OUTPUT_PATH, index=False)"
   ],
   "id": "9111d5526059f17f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28125it [4:15:41,  1.83it/s]                              \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T17:58:15.212599Z",
     "start_time": "2025-07-20T17:58:15.174583Z"
    }
   },
   "cell_type": "code",
   "source": "df.describe()",
   "id": "40e306144a0902a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           sentiment\n",
       "count  224994.000000\n",
       "mean        1.216655\n",
       "std         0.725744\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max         2.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>224994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.216655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.725744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
